{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ec8011-9e31-4ab2-a377-612ae39724f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple Linear Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       105\n",
      "           1       0.77      0.72      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       105\n",
      "           1       0.74      0.76      0.75        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       105\n",
      "           1       0.78      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       105\n",
      "           1       0.71      0.77      0.74        74\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.78      0.77       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n",
      "\n",
      "Support Vector Machine Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       105\n",
      "           1       0.82      0.72      0.76        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.80      0.81       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n",
      "\n",
      "KMeans Clustering (Adjusted Rand Index): 0.1118\n",
      "\n",
      "Model Accuracy Scores:\n",
      "Multiple Linear Regression (rounded): 0.7933\n",
      "Decision Tree: 0.7877\n",
      "K-Nearest Neighbors: 0.7989\n",
      "Naive Bayes: 0.7765\n",
      "Support Vector Machine: 0.8156\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Drop unhelpful columns\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Fill missing values using different strategies\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df['Fare'].fillna(df['Fare'].mean(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for column in categorical_cols:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Multiple Linear Regression\n",
    "mlr_model = LinearRegression()\n",
    "mlr_model.fit(X_train, y_train)\n",
    "mlr_pred = mlr_model.predict(X_test)\n",
    "\n",
    "mlr_pred_class = np.round(mlr_pred).astype(int)\n",
    "mlr_acc = accuracy_score(y_test, mlr_pred_class)\n",
    "\n",
    "print(\"\\nMultiple Linear Regression Classification Report:\")\n",
    "print(classification_report(y_test, mlr_pred_class))\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_pred))\n",
    "\n",
    "# 3. K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "# 4. Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "nb_acc = accuracy_score(y_test, nb_pred)\n",
    "\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, nb_pred))\n",
    "\n",
    "# 5. Support Vector Machine\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "# 6. Clustering (unsupervised)\n",
    "kmeans = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
    "kmeans.fit(X_scaled)\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "clustering_score = adjusted_rand_score(y, cluster_labels)\n",
    "\n",
    "print(f\"\\nKMeans Clustering (Adjusted Rand Index): {clustering_score:.4f}\")\n",
    "\n",
    "# Print model accuracy scores\n",
    "print(\"\\nModel Accuracy Scores:\")\n",
    "print(f\"Multiple Linear Regression (rounded): {mlr_acc:.4f}\")\n",
    "print(f\"Decision Tree: {dt_acc:.4f}\")\n",
    "print(f\"K-Nearest Neighbors: {knn_acc:.4f}\")\n",
    "print(f\"Naive Bayes: {nb_acc:.4f}\")\n",
    "print(f\"Support Vector Machine: {svm_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23ac5a-e193-45bf-8d45-85687fffb22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
