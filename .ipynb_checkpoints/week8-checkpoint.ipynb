{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac708b3e-d904-4c35-b59e-dea58722167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 - Target Categories: ['sci.space' 'comp.graphics' 'alt.atheism']\n",
      "\n",
      "Q9 - Training Set Target Names:\n",
      "    target       category\n",
      "0       2      sci.space\n",
      "1       1  comp.graphics\n",
      "2       0    alt.atheism\n",
      "\n",
      "Q10 - 5th Training Article:\n",
      " From: henry@zoo.toronto.edu (Henry Spencer)\n",
      "Subject: Re: TRUE \"GLOBE\", Who makes it?\n",
      "Organization: U of Toronto Zoology\n",
      "Lines: 12\n",
      "\n",
      "In article <bill.047m@xpresso.UUCP> bill@xpresso.UUCP (Bill Vance) writes:\n",
      ">It has been known for quite a while that the earth is actually more pear\n",
      ">shaped than globular/spherical.  Does anyone make a \"globe\" that is accurate\n",
      ">as to actual shape, landmass configuration/Long/Lat lines etc.?\n",
      "\n",
      "I don't think you're going to be able to see the differences from a sphere\n",
      "unless they are greatly exaggerated.  Even the equatorial bulge is only\n",
      "about 1 part in 300 -- you'd never notice a 1mm error in a 30cm globe --\n",
      "and the other deviations from spherical shape are much smaller.\n",
      "-- \n",
      "SVR4 resembles a high-speed collision   | Henry Spencer @ U of Toronto Zoology\n",
      "between SVR3 and SunOS.    - Dick Dunn  |  henry@zoo.toronto.edu  utzoo!henry\n",
      "\n",
      "\n",
      "Q11 - Training Data Shape: (1657, 3)\n",
      "Q11 - Testing Data Shape: (1102, 3)\n",
      "\n",
      "Q17 - Test Accuracy (CountVectorizer + BernoulliNB): 0.852994555353902\n",
      "\n",
      "Q19 - Test Accuracy (TF-IDF + MultinomialNB): 0.9473684210526315\n",
      "\n",
      "Q20 - Test Accuracy (TF-IDF + MultinomialNB, No Stopwords): 0.9555353901996371\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries (Q1)\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load datasets (Q2, Q3, Q4)\n",
    "train_data = pd.read_csv(\"newsgroups_train.csv\")\n",
    "test_data = pd.read_csv(\"newsgroups_test.csv\")\n",
    "\n",
    "# Print all target labels (Q5)\n",
    "print(\"Q5 - Target Categories:\", train_data['category'].unique())\n",
    "\n",
    "# Print training set target names (Q9)\n",
    "print(\"\\nQ9 - Training Set Target Names:\\n\", train_data[['target', 'category']].drop_duplicates())\n",
    "\n",
    "# Print 5th training article (Q10)\n",
    "print(\"\\nQ10 - 5th Training Article:\\n\", train_data.iloc[4]['text'])\n",
    "\n",
    "# Print shape of data (Q11)\n",
    "print(\"\\nQ11 - Training Data Shape:\", train_data.shape)\n",
    "print(\"Q11 - Testing Data Shape:\", test_data.shape)\n",
    "\n",
    "# Convert training data to numerical format using CountVectorizer (Q13)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(train_data['text'])\n",
    "X_test_counts = vectorizer.transform(test_data['text'])\n",
    "y_train = train_data['target']\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Train BernoulliNB model (Q14)\n",
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_nb.fit(X_train_counts, y_train)\n",
    "\n",
    "# Convert test data using CountVectorizer (Q15)\n",
    "# (Already transformed above)\n",
    "\n",
    "# Predict target labels for testing set (Q16)\n",
    "y_pred_counts = bernoulli_nb.predict(X_test_counts)\n",
    "\n",
    "# Find accuracy score on test set (Q17)\n",
    "accuracy_counts = accuracy_score(y_test, y_pred_counts)\n",
    "print(\"\\nQ17 - Test Accuracy (CountVectorizer + BernoulliNB):\", accuracy_counts)\n",
    "\n",
    "# Use TfidfVectorizer and train MultinomialNB (Q18)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['text'])\n",
    "\n",
    "multinomial_nb = MultinomialNB()\n",
    "multinomial_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate on test set (Q19)\n",
    "y_pred_tfidf = multinomial_nb.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(\"\\nQ19 - Test Accuracy (TF-IDF + MultinomialNB):\", accuracy_tfidf)\n",
    "\n",
    "# Avoid stopwords and repeat the process (Q20)\n",
    "tfidf_vectorizer_sw = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf_sw = tfidf_vectorizer_sw.fit_transform(train_data['text'])\n",
    "X_test_tfidf_sw = tfidf_vectorizer_sw.transform(test_data['text'])\n",
    "\n",
    "multinomial_nb_sw = MultinomialNB()\n",
    "multinomial_nb_sw.fit(X_train_tfidf_sw, y_train)\n",
    "\n",
    "# Predict and evaluate without stopwords\n",
    "y_pred_tfidf_sw = multinomial_nb_sw.predict(X_test_tfidf_sw)\n",
    "accuracy_tfidf_sw = accuracy_score(y_test, y_pred_tfidf_sw)\n",
    "print(\"\\nQ20 - Test Accuracy (TF-IDF + MultinomialNB, No Stopwords):\", accuracy_tfidf_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73233bb2-0436-42eb-89c7-207e8d0af052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
